{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 16.8MB/s]                    \n",
      "2021-04-15 10:45:08 INFO: Downloading default packages for language: en (English)...\n",
      "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/en/default.zip: 100%|██████████| 411M/411M [01:29<00:00, 4.57MB/s] \n",
      "2021-04-15 10:46:43 INFO: Finished downloading models and saved to /home/george/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-15 10:52:03 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-04-15 10:52:03 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2021-04-15 10:52:03 INFO: Use device: cpu\n",
      "2021-04-15 10:52:03 INFO: Loading: tokenize\n",
      "2021-04-15 10:52:03 INFO: Loading: pos\n",
      "2021-04-15 10:52:03 INFO: Loading: lemma\n",
      "2021-04-15 10:52:03 INFO: Loading: depparse\n",
      "2021-04-15 10:52:03 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Author\thead id: 3\thead: approaches\tdeprel: compound\n",
      "id: 2\tword: developed\thead id: 3\thead: approaches\tdeprel: amod\n",
      "id: 3\tword: approaches\thead id: 5\thead: based\tdeprel: nsubj:pass\n",
      "id: 4\tword: are\thead id: 5\thead: based\tdeprel: aux:pass\n",
      "id: 5\tword: based\thead id: 0\thead: root\tdeprel: root\n",
      "id: 6\tword: on\thead id: 10\thead: entity\tdeprel: case\n",
      "id: 7\tword: (\thead id: 8\thead: a\tdeprel: punct\n",
      "id: 8\tword: a\thead id: 10\thead: entity\tdeprel: nummod\n",
      "id: 9\tword: )\thead id: 8\thead: a\tdeprel: punct\n",
      "id: 10\tword: entity\thead id: 5\thead: based\tdeprel: obl\n",
      "id: 11\tword: matching\thead id: 10\thead: entity\tdeprel: acl\n",
      "id: 12\tword: using\thead id: 11\thead: matching\tdeprel: advcl\n",
      "id: 13\tword: an\thead id: 18\thead: database\tdeprel: det\n",
      "id: 14\tword: OpenStreetMap\thead id: 18\thead: database\tdeprel: compound\n",
      "id: 15\tword: (\thead id: 16\thead: OSM\tdeprel: punct\n",
      "id: 16\tword: OSM\thead id: 14\thead: OpenStreetMap\tdeprel: appos\n",
      "id: 17\tword: )\thead id: 16\thead: OSM\tdeprel: punct\n",
      "id: 18\tword: database\thead id: 12\thead: using\tdeprel: obj\n",
      "id: 19\tword: ,\thead id: 26\thead: model\tdeprel: punct\n",
      "id: 20\tword: and\thead id: 26\thead: model\tdeprel: cc\n",
      "id: 21\tword: (\thead id: 22\thead: b\tdeprel: punct\n",
      "id: 22\tword: b\thead id: 26\thead: model\tdeprel: dep\n",
      "id: 23\tword: )\thead id: 22\thead: b\tdeprel: punct\n",
      "id: 24\tword: a\thead id: 26\thead: model\tdeprel: det\n",
      "id: 25\tword: language\thead id: 26\thead: model\tdeprel: compound\n",
      "id: 26\tword: model\thead id: 18\thead: database\tdeprel: conj\n",
      "id: 27\tword: using\thead id: 26\thead: model\tdeprel: acl\n",
      "id: 28\tword: a\thead id: 29\thead: combination\tdeprel: det\n",
      "id: 29\tword: combination\thead id: 27\thead: using\tdeprel: obj\n",
      "id: 30\tword: of\thead id: 36\thead: dataset\tdeprel: case\n",
      "id: 31\tword: a\thead id: 36\thead: dataset\tdeprel: det\n",
      "id: 32\tword: large\thead id: 36\thead: dataset\tdeprel: amod\n",
      "id: 33\tword: social\thead id: 36\thead: dataset\tdeprel: amod\n",
      "id: 34\tword: media\thead id: 35\thead: tag\tdeprel: compound\n",
      "id: 35\tword: tag\thead id: 36\thead: dataset\tdeprel: compound\n",
      "id: 36\tword: dataset\thead id: 29\thead: combination\tdeprel: nmod\n",
      "id: 37\tword: and\thead id: 39\thead: gazetteers\tdeprel: cc\n",
      "id: 38\tword: multiple\thead id: 39\thead: gazetteers\tdeprel: amod\n",
      "id: 39\tword: gazetteers\thead id: 36\thead: dataset\tdeprel: conj\n",
      "id: 40\tword: .\thead id: 5\thead: based\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse', use_gpu = False)\n",
    "doc = nlp(\"Author developed approaches are based on (a) entity matching using an OpenStreetMap (OSM) database, and (b) a language model using a combination of a large social media tag dataset and multiple gazetteers.\")\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
