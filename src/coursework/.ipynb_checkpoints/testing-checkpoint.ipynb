{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "#os.listdir()\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = sorted(os.listdir(\"books\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-4-99e188fde203>, line 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-99e188fde203>\"\u001b[0;36m, line \u001b[0;32m64\u001b[0m\n\u001b[0;31m    i += 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def parse_toc_dict(book_name):\n",
    "    \n",
    "    #this is what will be built up and returned\n",
    "    toc_dict = {}\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    #the index of the string being looked at in the list of lines\n",
    "    i = 0\n",
    "        \n",
    "    with open(\"books/\" + book_name) as file:\n",
    "        lines = [line[1:] for line in file]\n",
    "    \n",
    "    n = len(lines)\n",
    "    \n",
    "    #first find the start of the table of contents\n",
    "    #for now, lets assume that every book will have a table of contents\n",
    "    contents_pattern = r\".*contents\\W*$\"\n",
    "\n",
    "    while(not re.match(contents_pattern, lines[i].lower())):\n",
    "        i += 1\n",
    "    \n",
    "    #we are not interested in the line of the table of contents so\n",
    "    # move onto the next line\n",
    "    i += 1\n",
    "    \n",
    "    #TABLE OF CONTENTS MEMBERS STAGE\n",
    "    \n",
    "    #for now, assume that each of the members are prepended with chapter\n",
    "    # or chapter\n",
    "    chapter_count = 1\n",
    "    \n",
    "    #either a digit or a roman numeral\n",
    "    number_regex = r\"(?:[ivxlcdm]+|[IVXLCDM]+|\\d+)\"\n",
    "\n",
    "    #on the first line, as contents members may span multiple lines\n",
    "    contents_member = (r\"\\s*(?:CHAPTER|chapter|Chapter)\\s*\" + \n",
    "        number_regex + \n",
    "        r\"\\s*\\.?\\s*([\\w\\s\\.\\'\\\"-]+)?$\")\n",
    "    contents_member = rcontents_member\n",
    "    \n",
    "    #check this line is not the start of another contents member or a blank line\n",
    "    member_span = (r\"?!(?:\\.*(CHAPTER|chapter|Chapter))?!(?:\\s*$)\" +\n",
    "                   r\"(.*)\")\n",
    "                # ^^ the bit that we actually want to capture\n",
    "    \n",
    "        # ^^^ the bit we want to capture, the name if any is listed in TOC\n",
    "        #we will store this in the dictionary with the name from TOC,\n",
    "        #but if any names are listed in the chapter headings as they appear\n",
    "        #then the dictionary value will be overridden with the string seen there\n",
    "    \n",
    "    matched = []\n",
    "    \n",
    "    while(i < n):\n",
    "        member_title = \"\"\n",
    "        res = re.match(contents_member, lines[i])\n",
    "        if(res):\n",
    "            member_title.append(res.group(1))\n",
    "            i += 1\n",
    "            while(re.match(member_span, )):\n",
    "                \n",
    "            \n",
    "            \n",
    "        i += 1\n",
    "        chapter_count += 1\n",
    "    \n",
    "    return list(map(lambda x: x.group(1), matched))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes an entire book as a string\n",
    "def test(book_name):\n",
    "    \n",
    "    toc_dict = {}\n",
    "    lines = []\n",
    "    \n",
    "    #we actually DO want to capture it, we don't however want to capture numbers as we will infer this later\n",
    "    #by iterating over the list of matches that we have found\n",
    "    chapter = r\"(Chapter|chapter|CHAPTER)\"\n",
    "    blank_line = r\"\\n\\n\"\n",
    "    \n",
    "    #The atomic numbers\n",
    "    number_letter_range = r\"[ONE|TWO|THREE|FOUR|FIVE|SIX|SEVEN|EIGHT|NINE|TEN|ELEVEN|TWELVE|THIRTEEN|FOURTEEN|FIFTEEN|SIXTEEN|SEVENTEEN|EIGHTEEN|NINETEEN]\"\n",
    "    base_number_range = r\"[TWENTY|THIRTY|FOURTY|FIFTY|SIXTY|SEVENTY|EIGHTY|NINETY]\"\n",
    "    number = r\"(?:[ivxlcdm]+|[IVXLCDM]+|\\d+)\"\n",
    "    contents_title = r\"^.*(?:contents|Contents|CONTENTS)\\W*$\"\n",
    "    \n",
    "    #the charcters which have been seen to appear in a title\n",
    "    chset = r\"[\\w\\.\\'\\\":]\"\n",
    "    \n",
    "    chapter_regex = r\"^\\s*\" + chapter + r\"\\s*\" + number + r\"\\W\\s*((?!\" + chapter_sep + \")[\\w\\.\\'\\\":])\"\n",
    "    \n",
    "    #check there isnt another chapter word coming up or a blank line gap\n",
    "    chapter_sep = chapter + r\"|\\n\\n\"\n",
    "    \n",
    "    chapter_end = \"()\"\n",
    "    \n",
    "    part_regex = r\"(^(PART|Part|part)\\s*\" + number + \")\"\n",
    "    \n",
    "    \n",
    "    my_flags = re.MULTILINE | re.DOTALL\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_v2(book_name):\n",
    "    \n",
    "    #matching phase is done now\n",
    "    \n",
    "    book_str = \"\"\n",
    "    \n",
    "    with open(\"books/\" + book_name, 'r') as f:\n",
    "        book_str = f.read()\n",
    "    \n",
    "    toc = r\"^.*(?:CONTENTS|Contents|contents)\\W*$\"\n",
    "    \n",
    "    #the type of information this text span is giving, we do indeed want to capture it\n",
    "    ty = r\"(CHAPTER|Chapter|chapter|BOOK|Book|book|PART|Part|part)\"\n",
    "\n",
    "    #either a roman numeral or digit, also allow for a single e.g. part A, volume B etc.\n",
    "    number = r\"([ivxlcdm]+|[IVXLCDM]+|\\d+|[A-Za-z])\"\n",
    "\n",
    "    #the charcters which have been seen to appear in titles I've looked at\n",
    "    chset = r\"[A-Za-z0-9\\?\\-\\.\\'\\\":“”’]\"\n",
    "    \n",
    "    #use \\1 to access the thing we are looking at as e.g. if we see a subsequent CHAPTER then clearly\n",
    "    #this is a seperator, or a \"blank line\" which is 2 new line characters (or \\r\\n in our case)\n",
    "    end_check =  r\"(?:?!(\\1|\\r\\n\\r\\n))\"\n",
    "    \n",
    "    #Each time we consume a newline, check to see if the \"type\" keyword is not after that newline\n",
    "    sep = r\"[ ]*((?!\\n\\s*\\1)\\n)?[ ]*\"\n",
    "    \n",
    "    #a word part of the text span, first check its not the end of the span\n",
    "    words = r\"((?:(?!CHAPTER)\" + chset + \"+\" + sep + \")*)\"\n",
    "        \n",
    "    #A text span for chapter/book/part\n",
    "    entity = r\"(?:^[ ]*(\" + ty + r\"\\s*\" + number + r\")\\W[ ]*\\n*\" + words + \")\" #+ r\"\\W[ ]*(?:\" + word + r\")*\" \n",
    "\n",
    "    matchings = [match_object for match_object in re.finditer(entity, book_str, flags = re.MULTILINE | re.DOTALL)]\n",
    "    \n",
    "    #the dictionary we will build up\n",
    "    dict = {}\n",
    "    \n",
    "    book_prefix = \"\"\n",
    "    vol_prefix = \"\"\n",
    "    part_prefix = \"\"\n",
    "    \n",
    "    return matchings\n",
    "    \n",
    "    #Group 0 is the whole string\n",
    "    #Group 1 is the whole prefix i.e. CHAPTER 1, BOOK whatever, part whatever e.t.c.\n",
    "    #Group 2 is the type\n",
    "    #Group 3 is the number\n",
    "    #Group 4 is the title\n",
    "    \n",
    "    #if a table of contents was detected\n",
    "    if toc:\n",
    "    \n",
    "        print(\"hello\")\n",
    "        \n",
    "    #if no table of contents was detected\n",
    "    else:\n",
    "        \n",
    "        for match in matchings:\n",
    "            if(match.group(1).lower() == \"book\"):\n",
    "                book_prefix = \"(\" + match.group(1) + \") \"\n",
    "                continue\n",
    "            if(match.group(1).lower() == \"volume\"):\n",
    "                vol_prefix = \"(\" + match.group(1) + \") \"\n",
    "                continue\n",
    "            if(match.group(1).lower() == \"part\"):\n",
    "                part_prefix = \"(\" + match.group(1) + \") \"\n",
    "                continue\n",
    "            #otherwise the type must be chapter\n",
    "            \n",
    "            #the chapter number mapped to the title\n",
    "            dict[match.group(3)] = match.group(4).replace('\\n', '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER I. Civilizing Huck.Miss Watson.Tom Sawyer Waits.',\n",
       " \"CHAPTER II. The Boys Escape Jim.--Torn Sawyer's Gang.--Deep-laid Plans.\",\n",
       " \"CHAPTER III. A Good Going-over.--Grace Triumphant.--“One of Tom Sawyers'sLies”.\",\n",
       " 'CHAPTER IV. Huck and the Judge.--Superstition.',\n",
       " \"CHAPTER V. Huck's Father.--The Fond Parent.--Reform.\",\n",
       " 'CHAPTER VI. He Went for Judge Thatcher.--Huck Decided to Leave.--PoliticalEconomy.--Thrashing Around.',\n",
       " 'CHAPTER VII. Laying for Him.--Locked in the Cabin.--Sinking theBody.--Resting.',\n",
       " \"CHAPTER VIII. Sleeping in the Woods.--Raising the Dead.--Exploring theIsland.--Finding Jim.--Jim's Escape.--Signs.--Balum.\",\n",
       " 'CHAPTER IX. The Cave.--The Floating House.',\n",
       " 'CHAPTER X. The Find.--Old Hank Bunker.--In Disguise.',\n",
       " 'CHAPTER XI. Huck and the Woman.--The Search.--Prevarication.--Going toGoshen.',\n",
       " 'CHAPTER XII. Slow Navigation.--Borrowing Things.--Boarding the Wreck.--ThePlotters.--Hunting for the Boat.',\n",
       " 'CHAPTER XIII. Escaping from the Wreck.--The Watchman.--Sinking.',\n",
       " 'CHAPTER XIV. A General Good Time.--The Harem.--French.',\n",
       " 'CHAPTER XV. Huck Loses the Raft.--In the Fog.--Huck Finds the Raft.--Trash.',\n",
       " 'CHAPTER XVI. Expectation.--A White Lie.--Floating Currency.--Running byCairo.--Swimming Ashore.',\n",
       " 'CHAPTER XVII. An Evening Call.--The Farm in Arkansaw.--InteriorDecorations.--Stephen Dowling Bots.--Poetical Effusions.',\n",
       " 'CHAPTER XVIII. Col. Grangerford.--Aristocracy.--Feuds.--TheTestament.--Recovering the Raft.--The Wood--pile.--Pork and Cabbage.',\n",
       " 'CHAPTER XIX. Tying Up Day--times.--An Astronomical Theory.--Running aTemperance Revival.--The Duke of Bridgewater.--The Troubles of Royalty.',\n",
       " 'CHAPTER XX. Huck Explains.--Laying Out a Campaign.--Working theCamp--meeting.--A Pirate at the Camp--meeting.--The Duke as a Printer.',\n",
       " \"CHAPTER XXI. Sword Exercise.--Hamlet's Soliloquy.--They Loafed AroundTown.--A Lazy Town.--Old Boggs.--Dead.\",\n",
       " 'CHAPTER XXII. Sherburn.--Attending the Circus.--Intoxication in theRing.--The Thrilling Tragedy.',\n",
       " 'CHAPTER XXIII. Sold.--Royal Comparisons.--Jim Gets Home-sick.',\n",
       " 'CHAPTER XXIV. Jim in Royal Robes.--They Take a Passenger.--GettingInformation.--Family Grief.',\n",
       " 'CHAPTER XXV. Is It Them?--Singing the “Doxologer.”--Awful Square--FuneralOrgies.--A Bad Investment .',\n",
       " \"CHAPTER XXVI. A Pious King.--The King's Clergy.--She Asked HisPardon.--Hiding in the Room.--Huck Takes the Money.\",\n",
       " 'CHAPTER XXVII. The Funeral.--Satisfying Curiosity.--Suspicious ofHuck',\n",
       " 'CHAPTER XXVIII. The Trip to England.--“The Brute',\n",
       " 'CHAPTER XXIX. Contested Relationship.--The King Explains the Loss.--AQuestion of Handwriting.--Digging up the Corpse.--Huck Escapes.',\n",
       " 'CHAPTER XXX. The King Went for Him.--A Royal Row.--Powerful Mellow.',\n",
       " 'CHAPTER XXXI. Ominous Plans.--News from Jim.--Old Recollections.--A SheepStory.--Valuable Information.',\n",
       " 'CHAPTER XXXII. Still and Sunday--like.--Mistaken Identity.--Up a Stump.--Ina Dilemma.',\n",
       " 'CHAPTER XXXIII. A Nigger Stealer.--Southern Hospitality.--A Pretty LongBlessing.--Tar and Feathers.',\n",
       " 'CHAPTER XXXIV. The Hut by the Ash Hopper.--Outrageous.--Climbing theLightning Rod.--Troubled with Witches.',\n",
       " 'CHAPTER XXXV. Escaping Properly.--Dark Schemes.--Discrimination inStealing.--A Deep Hole.',\n",
       " 'CHAPTER XXXVI. The Lightning Rod.--His Level Best.--A Bequest toPosterity.--A High Figure.',\n",
       " 'CHAPTER XXXVII. The Last Shirt.--Mooning Around.--Sailing Orders.--TheWitch Pie.',\n",
       " 'CHAPTER XXXVIII. The Coat of Arms.--A Skilled Superintendent.--UnpleasantGlory.--A Tearful Subject.',\n",
       " 'CHAPTER XXXIX. Rats.--Lively Bed--fellows.--The Straw Dummy.',\n",
       " 'CHAPTER XL. Fishing.--The Vigilance Committee.--A Lively Run.--Jim Advisesa Doctor.',\n",
       " 'CHAPTER XLI. The Doctor.--Uncle Silas.--Sister Hotchkiss.--Aunt Sally inTrouble.',\n",
       " \"CHAPTER XLII. Tom Sawyer Wounded.--The Doctor's Story.--TomConfesses.--Aunt Polly Arrives.--Hand Out Them Letters.\",\n",
       " \"CHAPTER I.You don't know about me without you have read a book by the name of TheAdventures of Tom Sawyer\",\n",
       " \"CHAPTER II.We went tiptoeing along a path amongst the trees back towards the end ofthe widow's garden\",\n",
       " \"books? Do you want to go to doing different from what's in the books\",\n",
       " 'CHAPTER III.Well',\n",
       " 'CHAPTER IV.Well',\n",
       " 'CHAPTER V.I had shut the door to. Then I turned around and there he was. I usedto be scared of him all the time',\n",
       " 'CHAPTER VI.Well',\n",
       " 'CHAPTER VII.“Git up',\n",
       " \"CHAPTER VIII.The sun was up so high when I waked that I judged it was after eighto'clock. I laid there in the grass and the cool shade thinking aboutthings\",\n",
       " \"CHAPTER IX.I wanted to go and look at a place right about the middle of the islandthat I'd found when I was exploring\",\n",
       " 'CHAPTER X.After breakfast I wanted to talk about the dead man and guess out how hecome to be killed',\n",
       " 'CHAPTER XI.“Come in',\n",
       " \"CHAPTER XII.It must a been close on to one o'clock when we got below the island atlast\",\n",
       " 'CHAPTER XIII.Well',\n",
       " 'CHAPTER XIV.By and by',\n",
       " 'CHAPTER XV.We judged that three nights more would fetch us to Cairo',\n",
       " 'CHAPTER XVI.We slept most all day',\n",
       " 'CHAPTER XVII.In about a minute somebody spoke out of a window without putting hishead out',\n",
       " 'CHAPTER XVIII.Col. Grangerford was a gentleman',\n",
       " 'CHAPTER XIX.Two or three days and nights went by',\n",
       " 'CHAPTER XX.They asked us considerable many questions',\n",
       " 'CHAPTER XXI.It was after sun-up now',\n",
       " \"CHAPTER XXII.They swarmed up towards Sherburn's house\",\n",
       " 'CHAPTER XXIII.Well',\n",
       " 'CHAPTER XXIV.Next day',\n",
       " 'CHAPTER XXV.The news was all over town in two minutes',\n",
       " 'CHAPTER XXVI.Well',\n",
       " 'CHAPTER XXVII.I crept to their doors and listened',\n",
       " 'CHAPTER XXVIII.By and by it was getting-up time. So I come down the ladder and startedfor down-stairs',\n",
       " 'CHAPTER XXIX.They was fetching a very nice-looking old gentleman along',\n",
       " 'CHAPTER XXX.When they got aboard the king went for me',\n",
       " \"CHAPTER XXXI.We dasn't stop again at any town for days and days\",\n",
       " 'CHAPTER XXXII.When I got there it was all still and Sunday-like',\n",
       " 'CHAPTER XXXIII.So I started for town in the wagon',\n",
       " 'CHAPTER XXXIV.We stopped talking',\n",
       " 'CHAPTER XXXV.It would be most an hour yet till breakfast',\n",
       " 'CHAPTER XXXVI.As soon as we reckoned everybody was asleep that night we went down thelightning-rod',\n",
       " 'CHAPTER XXXVII.That was all fixed. So then we went away and went to the rubbage-pilein the back yard',\n",
       " 'CHAPTER XXXVIII.Making them pens was a distressid tough job',\n",
       " 'CHAPTER XXXIX.In the morning we went up to the village and bought a wire rat-trap andfetched it down',\n",
       " 'CHAPTER XL.We was feeling pretty good after breakfast',\n",
       " 'CHAPTER XLI.The doctor was an old man',\n",
       " 'CHAPTER XLII.The old man was uptown again before breakfast']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simply remove leading and trailing spaces/newlines after regex matching and also remove inner new lines\n",
    "\n",
    "#val = parse_v2(books[1])\n",
    "#val\n",
    "#list(map(lambda x: x.group(1).replace('\\n', ''), parse_v2(books[1])))\n",
    "val = parse_v2(books[1])\n",
    "list(map(lambda x: x.group(0).replace('\\n', ''), val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adventures_of_huckleberry_finn.txt'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_questions(chapter_path):\n",
    "    \n",
    "    chapter_str = \"\"\n",
    "    \n",
    "    with open(chapter_path, 'r') as f:\n",
    "        chapter_str = f.read()\n",
    "    \n",
    "    #the set of characters that have been seen to come before a question\n",
    "    start_ch = r\"[\\?\\.\\'\\\"“”’!]\"\n",
    "    \n",
    "    #the set of characters that have been seen inside the body of a question\n",
    "    body = r\"[A-Za-z0-9’,]\"\n",
    "    \n",
    "    #Every question must begin with a capital letter\n",
    "    check = r\"([A-Z])\"\n",
    "    \n",
    "    inquotes = r\"(?:([\\'\\\"“”’])[A-Za-z0-9,\\s]*\\1)\"\n",
    "    noquotes = r\"(?:[A-Za-z0-9,\\s]*)\"\n",
    "    \n",
    "    #simple version, probably will end up doing this:\n",
    "    #[^\\?\\.,!]\n",
    "    \n",
    "    #Anything can be part of a question\n",
    "    question_regex = r\"[A-Z][^\\?\\.,!]*\\?\"\n",
    "    \n",
    "    return [match_object for match_object in re.finditer(question_regex, chapter_str, flags = re.MULTILINE | re.DOTALL)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(2608, 2638), match='What’s the report of this boy?'>,\n",
       " <re.Match object; span=(3234, 3249), match='Do YOU know me?'>,\n",
       " <re.Match object; span=(3250, 3254), match='Hey?'>,\n",
       " <re.Match object; span=(3370, 3378), match='Not yet?'>,\n",
       " <re.Match object; span=(3379, 3383), match='Hey?'>,\n",
       " <re.Match object; span=(3427, 3431), match='Hey?'>,\n",
       " <re.Match object; span=(3450, 3454), match='Hey?'>,\n",
       " <re.Match object; span=(4384, 4451), match='Has that fellow’--to the man with the wooden\\nleg>,\n",
       " <re.Match object; span=(5092, 5104), match='What’s this?'>,\n",
       " <re.Match object; span=(6544, 6553), match='Traddles?'>,\n",
       " <re.Match object; span=(7987, 7999), match='Copperfield?'>,\n",
       " <re.Match object; span=(8353, 8387), match='Do you want to spend anything now?'>,\n",
       " <re.Match object; span=(8883, 8894), match='I dare say?'>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_questions(\"eval_chapter.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE CODE STUART HAS PROVIDED IS BELOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys, codecs, json, math, time, warnings, re, logging\n",
    "warnings.simplefilter( action='ignore', category=FutureWarning )\n",
    "\n",
    "import nltk, numpy, scipy, sklearn, sklearn_crfsuite, sklearn_crfsuite.metrics\n",
    "\n",
    "LOG_FORMAT = ('%(levelname) -s %(asctime)s %(message)s')\n",
    "logger = logging.getLogger( __name__ )\n",
    "logging.basicConfig( level=logging.INFO, format=LOG_FORMAT )\n",
    "logger.info('logging started')\n",
    "\n",
    "def exec_ner( file_chapter = None, ontonotes_file = None ) :\n",
    "\n",
    "\t# INSERT CODE TO TRAIN A CRF NER MODEL TO TAG THE CHAPTER OF TEXT (subtask 3)\n",
    "\t# USING NER MODEL AND REGEX GENERATE A SET OF BOOK CHARACTERS AND FILTERED SET OF NE TAGS (subtask 4)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized (you should change this)\n",
    "\tdictNE = {\n",
    "\t\t\t\"CARDINAL\": [\n",
    "\t\t\t\t\"two\",\n",
    "\t\t\t\t\"three\",\n",
    "\t\t\t\t\"one\"\n",
    "\t\t\t],\n",
    "\t\t\t\"ORDINAL\": [\n",
    "\t\t\t\t\"first\"\n",
    "\t\t\t],\n",
    "\t\t\t\"DATE\": [\n",
    "\t\t\t\t\"saturday\",\n",
    "\t\t\t],\n",
    "\t\t\t\"NORP\": [\n",
    "\t\t\t\t\"indians\"\n",
    "\t\t\t],\n",
    "\t\t\t\"PERSON\": [\n",
    "\t\t\t\t\"creakle\",\n",
    "\t\t\t\t\"mr. creakle\",\n",
    "\t\t\t\t\"mrs. creakle\",\n",
    "\t\t\t\t\"miss creakle\"\n",
    "\t\t\t]\n",
    "\t\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\t# write out all PERSON entries for character list for subtask 4\n",
    "\twriteHandle = codecs.open( 'characters.txt', 'w', 'utf-8', errors = 'replace' )\n",
    "\tif 'PERSON' in dictNE :\n",
    "\t\tfor strNE in dictNE['PERSON'] :\n",
    "\t\t\twriteHandle.write( strNE.strip().lower()+ '\\n' )\n",
    "\twriteHandle.close()\n",
    "\n",
    "\t# FILTER NE dict by types required for subtask 3\n",
    "\tlistAllowedTypes = [ 'DATE', 'CARDINAL', 'ORDINAL', 'NORP' ]\n",
    "\tlistKeys = list( dictNE.keys() )\n",
    "\tfor strKey in listKeys :\n",
    "\t\tfor nIndex in range(len(dictNE[strKey])) :\n",
    "\t\t\tdictNE[strKey][nIndex] = dictNE[strKey][nIndex].strip().lower()\n",
    "\t\tif not strKey in listAllowedTypes :\n",
    "\t\t\tdel dictNE[strKey]\n",
    "\n",
    "\t# write filtered NE dict\n",
    "\twriteHandle = codecs.open( 'ne.json', 'w', 'utf-8', errors = 'replace' )\n",
    "\tstrJSON = json.dumps( dictNE, indent=2 )\n",
    "\twriteHandle.write( strJSON + '\\n' )\n",
    "\twriteHandle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "\n",
    "def exec_regex_toc( file_book = None ) :\n",
    "\n",
    "\t# INSERT CODE TO USE REGEX TO BUILD A TABLE OF CONTENTS FOR A BOOK (subtask 1)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized\n",
    "    #so change this dictionary to the chapter and number pairs that we find\n",
    "    \n",
    "\tdictTOC = {\n",
    "\t\t\t\"1\": \"I AM BORN\",\n",
    "\t\t\t\"2\": \"I OBSERVE\",\n",
    "\t\t\t\"3\": \"I HAVE A CHANGE\"\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\twriteHandle = codecs.open( 'toc.json', 'w', 'utf-8', errors = 'replace' )\n",
    "\tstrJSON = json.dumps( dictTOC, indent=2 )\n",
    "\twriteHandle.write( strJSON + '\\n' )\n",
    "\twriteHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 2\n",
    "\n",
    "def exec_regex_questions( file_chapter = None ) :\n",
    "\n",
    "\t# INSERT CODE TO USE REGEX TO LIST ALL QUESTIONS IN THE CHAPTER OF TEXT (subtask 2)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized\n",
    "\tsetQuestions = set([\n",
    "\t\t\"Traddles?\",\n",
    "\t\t\"And another shilling or so in biscuits, and another in fruit, eh?\",\n",
    "\t\t\"Perhaps you’d like to spend a couple of shillings or so, in a bottle of currant wine by and by, up in the bedroom?\",\n",
    "\t\t\"Has that fellow’--to the man with the wooden leg--‘been here again?\"\n",
    "\t\t])\n",
    "\n",
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\twriteHandle = codecs.open( 'questions.txt', 'w', 'utf-8', errors = 'replace' )\n",
    "\tfor strQuestion in setQuestions :\n",
    "\t\twriteHandle.write( strQuestion + '\\n' )\n",
    "\twriteHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\tif len(sys.argv) < 4 :\n",
    "\t\traise Exception( 'missing command line args : ' + repr(sys.argv) )\n",
    "\tontonotes_file = sys.argv[1]\n",
    "\tbook_file = sys.argv[2]\n",
    "\tchapter_file = sys.argv[3]\n",
    "\n",
    "\tlogger.info( 'ontonotes = ' + repr(ontonotes_file) )\n",
    "\tlogger.info( 'book = ' + repr(book_file) )\n",
    "\tlogger.info( 'chapter = ' + repr(chapter_file) )\n",
    "\n",
    "\t# DO NOT CHANGE THE CODE IN THIS FUNCTION\n",
    "\n",
    "\t#\n",
    "\t# subtask 1 >> extract chapter headings and create a table of contents from a provided plain text book (from www.gutenberg.org)\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a whole book\n",
    "\t# Output >> toc.json = { <chapter_number_text> : <chapter_title_text> }\n",
    "\t#\n",
    "\n",
    "\texec_regex_toc( book_file )\n",
    "\n",
    "\t#\n",
    "\t# subtask 2 >> extract every question from a provided plain text chapter of text\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> questions.txt = plain text set of extracted questions. one line per question.\n",
    "\t#\n",
    "\n",
    "\texec_regex_questions( chapter_file )\n",
    "\n",
    "\t#\n",
    "\t# subtask 3 (NER) >> train NER using ontonotes dataset, then extract DATE, CARDINAL, ORDINAL, NORP entities from a provided chapter of text\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> ne.json = { <ne_type> : [ <phrase>, <phrase>, ... ] }\n",
    "\t#\n",
    "\t# subtask 4 (text classifier) >> compile a list of characters from the target chapter\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> characters.txt = plain text set of extracted character names. one line per character name.\n",
    "\t#\n",
    "\n",
    "\texec_ner( chapter_file, ontonotes_file )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
