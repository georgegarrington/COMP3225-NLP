{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "#os.listdir()\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = sorted(os.listdir(\"books\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_toc_dict(book_name):\n",
    "    \n",
    "    #this is what will be built up and returned\n",
    "    toc_dict = {}\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    #the index of the string being looked at in the list of lines\n",
    "    i = 0\n",
    "        \n",
    "    with open(\"books/\" + book_name) as file:\n",
    "        lines = [line.rstrip() for line in file]\n",
    "    \n",
    "    n = len(lines)\n",
    "    \n",
    "    #first find the start of the table of contents\n",
    "    #for now, lets assume that every book will have a table of contents\n",
    "    contents_pattern = r\".*contents\\W*$\"\n",
    "\n",
    "    while(not re.match(contents_pattern, lines[i].lower())):\n",
    "        i += 1\n",
    "    \n",
    "    #we are not interested in the line of the table of contents so\n",
    "    # move onto the next line\n",
    "    i += 1\n",
    "    \n",
    "    #TABLE OF CONTENTS MEMBERS STAGE\n",
    "    \n",
    "    #for now, assume that each of the members are prepended with chapter\n",
    "    # or chapter\n",
    "    chapter_count = 1\n",
    "    \n",
    "    #either a digit or a roman numeral\n",
    "    number_regex = r\"(?:[ivxlcdm]+|[IVXLCDM]+|\\d+)\"\n",
    "\n",
    "    #on the first line, as contents members may span multiple lines\n",
    "    contents_member = (r\"\\s*(?:CHAPTER|chapter|Chapter)\\s*\" + \n",
    "        number_regex + \n",
    "        r\"\\s*\\.?\\s*([\\w\\s\\.\\'\\\"-]+)?$\")\n",
    "    contents_member = rcontents_member\n",
    "    \n",
    "    #check this line is not the start of another contents member or a blank line\n",
    "    member_span = (r\"?!(?:\\.*(CHAPTER|chapter|Chapter))?!(?:\\s*$)\" +\n",
    "                   r\"(.*)\")\n",
    "                # ^^ the bit that we actually want to capture\n",
    "    \n",
    "        # ^^^ the bit we want to capture, the name if any is listed in TOC\n",
    "        #we will store this in the dictionary with the name from TOC,\n",
    "        #but if any names are listed in the chapter headings as they appear\n",
    "        #then the dictionary value will be overridden with the string seen there\n",
    "    \n",
    "    matched = []\n",
    "    \n",
    "    while(i < n):\n",
    "        member_title = \"\"\n",
    "        res = re.match(contents_member, lines[i])\n",
    "        if(res):\n",
    "            member_title.append(res.group(1))\n",
    "            i += 1\n",
    "            while(re.match(member_span, )):\n",
    "                \n",
    "            \n",
    "            \n",
    "        i += 1\n",
    "        chapter_count += 1\n",
    "    \n",
    "    return list(map(lambda x: x.group(1), matched))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    toc_dict = {}\n",
    "    lines = []\n",
    "    \n",
    "    contents_title = r\".*(?:contents|Contents|CONTENTS)\\W*$\"\n",
    "    contents_member = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Civilizing Huck.Miss Watson.Tom Sawyer Waits.',\n",
       " \"The Boys Escape Jim.--Torn Sawyer's Gang.--Deep-laid Plans.\",\n",
       " 'Huck and the Judge.--Superstition.',\n",
       " \"Huck's Father.--The Fond Parent.--Reform.\",\n",
       " 'He Went for Judge Thatcher.--Huck Decided to Leave.--Political',\n",
       " 'Laying for Him.--Locked in the Cabin.--Sinking the',\n",
       " 'Sleeping in the Woods.--Raising the Dead.--Exploring the',\n",
       " 'The Cave.--The Floating House.',\n",
       " 'The Find.--Old Hank Bunker.--In Disguise.',\n",
       " 'Huck and the Woman.--The Search.--Prevarication.--Going to',\n",
       " 'Slow Navigation.--Borrowing Things.--Boarding the Wreck.--The',\n",
       " 'Escaping from the Wreck.--The Watchman.--Sinking.',\n",
       " 'A General Good Time.--The Harem.--French.',\n",
       " 'Huck Loses the Raft.--In the Fog.--Huck Finds the Raft.--Trash.',\n",
       " 'Expectation.--A White Lie.--Floating Currency.--Running by',\n",
       " 'An Evening Call.--The Farm in Arkansaw.--Interior',\n",
       " 'Col. Grangerford.--Aristocracy.--Feuds.--The',\n",
       " 'Tying Up Day--times.--An Astronomical Theory.--Running a',\n",
       " 'Huck Explains.--Laying Out a Campaign.--Working the',\n",
       " \"Sword Exercise.--Hamlet's Soliloquy.--They Loafed Around\",\n",
       " 'Sherburn.--Attending the Circus.--Intoxication in the',\n",
       " 'Sold.--Royal Comparisons.--Jim Gets Home-sick.',\n",
       " 'Jim in Royal Robes.--They Take a Passenger.--Getting',\n",
       " \"A Pious King.--The King's Clergy.--She Asked His\",\n",
       " 'The Funeral.--Satisfying Curiosity.--Suspicious of',\n",
       " 'Contested Relationship.--The King Explains the Loss.--A',\n",
       " 'The King Went for Him.--A Royal Row.--Powerful Mellow.',\n",
       " 'Ominous Plans.--News from Jim.--Old Recollections.--A Sheep',\n",
       " 'Still and Sunday--like.--Mistaken Identity.--Up a Stump.--In',\n",
       " 'A Nigger Stealer.--Southern Hospitality.--A Pretty Long',\n",
       " 'The Hut by the Ash Hopper.--Outrageous.--Climbing the',\n",
       " 'Escaping Properly.--Dark Schemes.--Discrimination in',\n",
       " 'The Lightning Rod.--His Level Best.--A Bequest to',\n",
       " 'The Last Shirt.--Mooning Around.--Sailing Orders.--The',\n",
       " 'The Coat of Arms.--A Skilled Superintendent.--Unpleasant',\n",
       " 'Rats.--Lively Bed--fellows.--The Straw Dummy.',\n",
       " 'Fishing.--The Vigilance Committee.--A Lively Run.--Jim Advises',\n",
       " 'The Doctor.--Uncle Silas.--Sister Hotchkiss.--Aunt Sally in',\n",
       " \"Tom Sawyer Wounded.--The Doctor's Story.--Tom\",\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_toc_dict(books[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE CODE STUART HAS PROVIDED IS BELOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys, codecs, json, math, time, warnings, re, logging\n",
    "warnings.simplefilter( action='ignore', category=FutureWarning )\n",
    "\n",
    "import nltk, numpy, scipy, sklearn, sklearn_crfsuite, sklearn_crfsuite.metrics\n",
    "\n",
    "LOG_FORMAT = ('%(levelname) -s %(asctime)s %(message)s')\n",
    "logger = logging.getLogger( __name__ )\n",
    "logging.basicConfig( level=logging.INFO, format=LOG_FORMAT )\n",
    "logger.info('logging started')\n",
    "\n",
    "def exec_ner( file_chapter = None, ontonotes_file = None ) :\n",
    "\n",
    "\t# INSERT CODE TO TRAIN A CRF NER MODEL TO TAG THE CHAPTER OF TEXT (subtask 3)\n",
    "\t# USING NER MODEL AND REGEX GENERATE A SET OF BOOK CHARACTERS AND FILTERED SET OF NE TAGS (subtask 4)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized (you should change this)\n",
    "\tdictNE = {\n",
    "\t\t\t\"CARDINAL\": [\n",
    "\t\t\t\t\"two\",\n",
    "\t\t\t\t\"three\",\n",
    "\t\t\t\t\"one\"\n",
    "\t\t\t],\n",
    "\t\t\t\"ORDINAL\": [\n",
    "\t\t\t\t\"first\"\n",
    "\t\t\t],\n",
    "\t\t\t\"DATE\": [\n",
    "\t\t\t\t\"saturday\",\n",
    "\t\t\t],\n",
    "\t\t\t\"NORP\": [\n",
    "\t\t\t\t\"indians\"\n",
    "\t\t\t],\n",
    "\t\t\t\"PERSON\": [\n",
    "\t\t\t\t\"creakle\",\n",
    "\t\t\t\t\"mr. creakle\",\n",
    "\t\t\t\t\"mrs. creakle\",\n",
    "\t\t\t\t\"miss creakle\"\n",
    "\t\t\t]\n",
    "\t\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\t# write out all PERSON entries for character list for subtask 4\n",
    "\twriteHandle = codecs.open( 'characters.txt', 'w', 'utf-8', errors = 'replace' )\n",
    "\tif 'PERSON' in dictNE :\n",
    "\t\tfor strNE in dictNE['PERSON'] :\n",
    "\t\t\twriteHandle.write( strNE.strip().lower()+ '\\n' )\n",
    "\twriteHandle.close()\n",
    "\n",
    "\t# FILTER NE dict by types required for subtask 3\n",
    "\tlistAllowedTypes = [ 'DATE', 'CARDINAL', 'ORDINAL', 'NORP' ]\n",
    "\tlistKeys = list( dictNE.keys() )\n",
    "\tfor strKey in listKeys :\n",
    "\t\tfor nIndex in range(len(dictNE[strKey])) :\n",
    "\t\t\tdictNE[strKey][nIndex] = dictNE[strKey][nIndex].strip().lower()\n",
    "\t\tif not strKey in listAllowedTypes :\n",
    "\t\t\tdel dictNE[strKey]\n",
    "\n",
    "\t# write filtered NE dict\n",
    "\twriteHandle = codecs.open( 'ne.json', 'w', 'utf-8', errors = 'replace' )\n",
    "\tstrJSON = json.dumps( dictNE, indent=2 )\n",
    "\twriteHandle.write( strJSON + '\\n' )\n",
    "\twriteHandle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "\n",
    "def exec_regex_toc( file_book = None ) :\n",
    "\n",
    "\t# INSERT CODE TO USE REGEX TO BUILD A TABLE OF CONTENTS FOR A BOOK (subtask 1)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized\n",
    "    #so change this dictionary to the chapter and number pairs that we find\n",
    "    \n",
    "\tdictTOC = {\n",
    "\t\t\t\"1\": \"I AM BORN\",\n",
    "\t\t\t\"2\": \"I OBSERVE\",\n",
    "\t\t\t\"3\": \"I HAVE A CHANGE\"\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\twriteHandle = codecs.open( 'toc.json', 'w', 'utf-8', errors = 'replace' )\n",
    "\tstrJSON = json.dumps( dictTOC, indent=2 )\n",
    "\twriteHandle.write( strJSON + '\\n' )\n",
    "\twriteHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 2\n",
    "\n",
    "def exec_regex_questions( file_chapter = None ) :\n",
    "\n",
    "\t# INSERT CODE TO USE REGEX TO LIST ALL QUESTIONS IN THE CHAPTER OF TEXT (subtask 2)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized\n",
    "\tsetQuestions = set([\n",
    "\t\t\"Traddles?\",\n",
    "\t\t\"And another shilling or so in biscuits, and another in fruit, eh?\",\n",
    "\t\t\"Perhaps you’d like to spend a couple of shillings or so, in a bottle of currant wine by and by, up in the bedroom?\",\n",
    "\t\t\"Has that fellow’--to the man with the wooden leg--‘been here again?\"\n",
    "\t\t])\n",
    "\n",
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\twriteHandle = codecs.open( 'questions.txt', 'w', 'utf-8', errors = 'replace' )\n",
    "\tfor strQuestion in setQuestions :\n",
    "\t\twriteHandle.write( strQuestion + '\\n' )\n",
    "\twriteHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\tif len(sys.argv) < 4 :\n",
    "\t\traise Exception( 'missing command line args : ' + repr(sys.argv) )\n",
    "\tontonotes_file = sys.argv[1]\n",
    "\tbook_file = sys.argv[2]\n",
    "\tchapter_file = sys.argv[3]\n",
    "\n",
    "\tlogger.info( 'ontonotes = ' + repr(ontonotes_file) )\n",
    "\tlogger.info( 'book = ' + repr(book_file) )\n",
    "\tlogger.info( 'chapter = ' + repr(chapter_file) )\n",
    "\n",
    "\t# DO NOT CHANGE THE CODE IN THIS FUNCTION\n",
    "\n",
    "\t#\n",
    "\t# subtask 1 >> extract chapter headings and create a table of contents from a provided plain text book (from www.gutenberg.org)\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a whole book\n",
    "\t# Output >> toc.json = { <chapter_number_text> : <chapter_title_text> }\n",
    "\t#\n",
    "\n",
    "\texec_regex_toc( book_file )\n",
    "\n",
    "\t#\n",
    "\t# subtask 2 >> extract every question from a provided plain text chapter of text\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> questions.txt = plain text set of extracted questions. one line per question.\n",
    "\t#\n",
    "\n",
    "\texec_regex_questions( chapter_file )\n",
    "\n",
    "\t#\n",
    "\t# subtask 3 (NER) >> train NER using ontonotes dataset, then extract DATE, CARDINAL, ORDINAL, NORP entities from a provided chapter of text\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> ne.json = { <ne_type> : [ <phrase>, <phrase>, ... ] }\n",
    "\t#\n",
    "\t# subtask 4 (text classifier) >> compile a list of characters from the target chapter\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> characters.txt = plain text set of extracted character names. one line per character name.\n",
    "\t#\n",
    "\n",
    "\texec_ner( chapter_file, ontonotes_file )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
