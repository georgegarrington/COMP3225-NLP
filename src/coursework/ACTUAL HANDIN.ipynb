{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2021-05-08 18:09:34,498 logging started\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys, codecs, json, math, time, warnings, re, logging\n",
    "warnings.simplefilter( action='ignore', category=FutureWarning )\n",
    "\n",
    "import nltk, numpy, scipy, sklearn, sklearn_crfsuite, sklearn_crfsuite.metrics\n",
    "\n",
    "LOG_FORMAT = ('%(levelname) -s %(asctime)s %(message)s')\n",
    "logger = logging.getLogger( __name__ )\n",
    "logging.basicConfig( level=logging.INFO, format=LOG_FORMAT )\n",
    "logger.info('logging started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_toc(chapter_str):\n",
    "    \n",
    "    chapter = r\"(?:CHAPTER|(C|c)hapter)\"\n",
    "    \n",
    "    #either roman numerals or a digit\n",
    "    num = r\"([ivxlcdm]+|[IVXLCDM]+|\\d+)\"\n",
    "    \n",
    "    #the charcters which have been seen to appear in titles I've looked at\n",
    "    #OR match any non-ASCII character (i.e. the special unicode apostraphes\n",
    "    #that often appear)\n",
    "    #chset = r\"(?:[A-Za-z0-9\\?\\-\\.\\'\\\":“”’ ]|[^\\x00-\\x7F])\"\n",
    "    chset = \"[^\\n]\"\n",
    "    \n",
    "    regex = \"\".join([\n",
    "        chapter, r\"[ ]*\", num, r\"[ ]*\\.?[ ]*\\n*[ ]*\",\n",
    "        r\"([A-Za-z]\", chset, \"*)\"\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        mobj.groups()[1] : mobj.groups()[2] \n",
    "        for mobj in re.finditer(regex, chapter_str)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given an entire chapter that has been read as a string, \n",
    "#extract all questions from it\n",
    "def extract_questions(chapter_str):\n",
    "    \n",
    "    #Start with a capital letter, any number of non-sentence ending characters followed by a question mark\n",
    "    regex = r\"(?:(?<=([‘“\\\"\\'\\.\\?\\!]))[ ]*)([A-Z][^\\?\\.!]*\\?)\"\n",
    "    matches = re.findall(regex, chapter_str, flags = re.MULTILINE | re.DOTALL | re.UNICODE)\n",
    "    return set(match.replace('\\n', ' ') for _, match in matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_ner( file_chapter = None, ontonotes_file = None ) :\n",
    "\n",
    "\t# INSERT CODE TO TRAIN A CRF NER MODEL TO TAG THE CHAPTER OF TEXT (subtask 3)\n",
    "\t# USING NER MODEL AND REGEX GENERATE A SET OF BOOK CHARACTERS AND FILTERED SET OF NE TAGS (subtask 4)\n",
    "\n",
    "\t# hardcoded output to show exactly what is expected to be serialized (you should change this)\n",
    "\tdictNE = {\n",
    "\t\t\t\"CARDINAL\": [\n",
    "\t\t\t\t\"two\",\n",
    "\t\t\t\t\"three\",\n",
    "\t\t\t\t\"one\"\n",
    "\t\t\t],\n",
    "\t\t\t\"ORDINAL\": [\n",
    "\t\t\t\t\"first\"\n",
    "\t\t\t],\n",
    "\t\t\t\"DATE\": [\n",
    "\t\t\t\t\"saturday\",\n",
    "\t\t\t],\n",
    "\t\t\t\"NORP\": [\n",
    "\t\t\t\t\"indians\"\n",
    "\t\t\t],\n",
    "\t\t\t\"PERSON\": [\n",
    "\t\t\t\t\"creakle\",\n",
    "\t\t\t\t\"mr. creakle\",\n",
    "\t\t\t\t\"mrs. creakle\",\n",
    "\t\t\t\t\"miss creakle\"\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\t# write out all PERSON entries for character list for subtask 4\n",
    "\twriteHandle = codecs.open( 'characters.txt', 'w', 'utf-8', errors = 'replace' )\n",
    "\tif 'PERSON' in dictNE :\n",
    "\t\tfor strNE in dictNE['PERSON'] :\n",
    "\t\t\twriteHandle.write( strNE.strip().lower()+ '\\n' )\n",
    "\twriteHandle.close()\n",
    "\n",
    "\t# FILTER NE dict by types required for subtask 3\n",
    "\tlistAllowedTypes = [ 'DATE', 'CARDINAL', 'ORDINAL', 'NORP' ]\n",
    "\tlistKeys = list( dictNE.keys() )\n",
    "\tfor strKey in listKeys :\n",
    "\t\tfor nIndex in range(len(dictNE[strKey])) :\n",
    "\t\t\tdictNE[strKey][nIndex] = dictNE[strKey][nIndex].strip().lower()\n",
    "\t\tif not strKey in listAllowedTypes :\n",
    "\t\t\tdel dictNE[strKey]\n",
    "\n",
    "\t# write filtered NE dict\n",
    "\twriteHandle = codecs.open( 'ne.json', 'w', 'utf-8', errors = 'replace' )\n",
    "\tstrJSON = json.dumps( dictNE, indent=2 )\n",
    "\twriteHandle.write( strJSON + '\\n' )\n",
    "\twriteHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_regex_toc( file_book = None ) :\n",
    "\n",
    "\tbook_str = \"\"\n",
    "\twith open(file_book, 'r') as f:\n",
    "\t\tbook_str = f.read()\n",
    "\t\n",
    "\tdictTOC = extract_toc(book_str)\n",
    "\n",
    "\t# DO NOT CHANGE THE BELOW CODE WHICH WILL SERIALIZE THE ANSWERS FOR THE AUTOMATED TEST HARNESS TO LOAD AND MARK\n",
    "\n",
    "\twriteHandle = codecs.open( 'toc.json', 'w', 'utf-8', errors = 'replace' )\n",
    "\tstrJSON = json.dumps( dictTOC, indent=2 )\n",
    "\twriteHandle.write( strJSON + '\\n' )\n",
    "\twriteHandle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_regex_questions( file_chapter = None ) :\n",
    "\n",
    "\tchapter_str = \"\"\n",
    "\twith open(file_chapter, 'r') as f:\n",
    "\t\tchapter_str = f.read()\n",
    "\t\n",
    "\tsetQuestions = extract_questions(chapter_str)\n",
    "\n",
    "\twriteHandle = codecs.open( 'questions.txt', 'w', 'utf-8', errors = 'replace' )\n",
    "\tfor strQuestion in setQuestions :\n",
    "\t\twriteHandle.write( strQuestion + '\\n' )\n",
    "\twriteHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "missing command line args : ['/home/george/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/george/.local/share/jupyter/runtime/kernel-d2c2690f-2390-4eb5-95cb-bd3464195744.json']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bfeda2af65ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'missing command line args : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0montonotes_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbook_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: missing command line args : ['/home/george/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/george/.local/share/jupyter/runtime/kernel-d2c2690f-2390-4eb5-95cb-bd3464195744.json']"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tif len(sys.argv) < 4 :\n",
    "\t\traise Exception( 'missing command line args : ' + repr(sys.argv) )\n",
    "\tontonotes_file = sys.argv[1]\n",
    "\tbook_file = sys.argv[2]\n",
    "\tchapter_file = sys.argv[3]\n",
    "\n",
    "\tlogger.info( 'ontonotes = ' + repr(ontonotes_file) )\n",
    "\tlogger.info( 'book = ' + repr(book_file) )\n",
    "\tlogger.info( 'chapter = ' + repr(chapter_file) )\n",
    "\n",
    "\t# DO NOT CHANGE THE CODE IN THIS FUNCTION\n",
    "\n",
    "\t#\n",
    "\t# subtask 1 >> extract chapter headings and create a table of contents from a provided plain text book (from www.gutenberg.org)\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a whole book\n",
    "\t# Output >> toc.json = { <chapter_number_text> : <chapter_title_text> }\n",
    "\t#\n",
    "\n",
    "\texec_regex_toc( book_file )\n",
    "\n",
    "\t#\n",
    "\t# subtask 2 >> extract every question from a provided plain text chapter of text\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> questions.txt = plain text set of extracted questions. one line per question.\n",
    "\t#\n",
    "\n",
    "\texec_regex_questions( chapter_file )\n",
    "\n",
    "\t#\n",
    "\t# subtask 3 (NER) >> train NER using ontonotes dataset, then extract DATE, CARDINAL, ORDINAL, NORP entities from a provided chapter of text\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> ne.json = { <ne_type> : [ <phrase>, <phrase>, ... ] }\n",
    "\t#\n",
    "\t# subtask 4 (text classifier) >> compile a list of characters from the target chapter\n",
    "\t# Input >> www.gutenberg.org sourced plain text file for a chapter of a book\n",
    "\t# Output >> characters.txt = plain text set of extracted character names. one line per character name.\n",
    "\t#\n",
    "\n",
    "\texec_ner( chapter_file, ontonotes_file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
